FROM mcr.microsoft.com/mmlspark/release

ENV SPARK_VERSION=3.0.1

RUN apt-get update && \
    apt-get install -y --no-install-recommends curl && \
    rm -rf /var/lib/apt/lists/*

RUN curl -L http://apache.spinellicreations.com/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop2.7.tgz -o spark-${SPARK_VERSION}-bin-hadoop2.7.tgz

RUN tar -xzf spark-${SPARK_VERSION}-bin-hadoop2.7.tgz && \
    mv spark-${SPARK_VERSION}-bin-hadoop2.7 /spark && \
    rm spark-${SPARK_VERSION}-bin-hadoop2.7.tgz && \
    conda update -n base -y conda && \
    conda install -y -c conda-forge plotly jupyterlab jupyterlab-dash widgetsnbextension nodejs ipywidgets "openjdk=8.0.192"  && \ 
    mkdir -p /etc/conf.d/hadoop

ENV SPARK_HOME="/spark"
ENV PYSPARK_PYTHON="/usr/local/bin/python"
ENV PYSPARK_DRIVER_PYTHON="jupyter"
ENV PYSPARK_DRIVER_PYTHON_OPTS="notebook"
ENV JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64
#ENV JAVA_HOME="/usr/lib/jvm/java-1.8-openjdk"
ENV HADOOP_CONF_DIR="/etc/conf.d/hadoop"

COPY start-master.sh /start-master.sh
COPY start-worker.sh /start-worker.sh
COPY ./conf/ /etc/conf.d/hadoop

